---
title: 'Lesson 4 分类'
date: 2026-01-28
permalink: /posts/2026/01/2026-01-28-Lesson-4-分类/
excerpt: "有点无聊……"
tags:
---

# 分类：Logistic 回归

> 给定一个样本 $x$，它的类别 $y$ 要么是 $0$ 要么是 $1$，但是我不知道它具体是哪个类别。我希望根据以往的数据，求出
>
> $$P(y = 1 \mid x)$$
>
> 若这个值 $\ge \frac 1 2$，我就把 $x$ 归类到 $1$，否则归类到 $0$。

## 问题设计

一个简单的想法：我直接用上节课学过的线性回归拟合一条直线出来不就好了吗？

$$\hat y = w^T x + b$$

但这个想法是错的，因为这样得到的 $\hat y$ 不一定落在 $[0,1]$ 之间（别忘记我们要算的是概率！）。

也就是说，我们要找一个这样的函数对结果进行“压缩”：
- 定义域 $\mathbb R$
- 值域 $[0,1]$
- 单调递增

我们发现 **Sigmoid 函数**是一个不错的选择：

$$\boxed{
    \sigma(x) := \frac 1 {1 + e^{-x}}
}$$

它处处可导，而且导函数可以用自身表示，后续 GD 中可以减少计算量：

$$\boxed{
    \sigma'(x) = \sigma(x) (1 - \sigma(x))
}$$

我们重新利用 Sigmoid 函数表述：

$$\boxed{
    P(y = 1 \mid x) = h(x) = \sigma(w^T x + b)
}$$

值得一提的是，这里的 Sigmoid 不是必需的，可以换成其它同样符合值域限制和单调性的函数，比如正态分布 CDF 的反函数。

## 求解

首先使用和 Lesson 3 一样的小技巧把 $b$ 打包到 $w$，不赘述。

对于单个样本，其似然函数为：

$$P(y \mid p) = \begin{cases}
    p & y = 1 \\
    1-p & y = 0 \\
\end{cases} = p^y (1-p)^{1-y}$$

我们用 $h(x)$ 代替 $p$：

$$L_i(w) = h(x_i)^{y_i} (1 - h(x_i))^{1-y_i}$$

所有样本的联合似然函数即为：

$$L(w) = \prod_{i=1}^n L_i(w) = \prod_{i=1}^n h(x_i)^{y_i} (1 - h(x_i))^{1 - y_i}$$

作**最大似然估计**：

$$\begin{aligned}
    \hat w =& \arg \max_w L(w) \\
    =& \arg \max_w \ln L(w) \\
    =& \arg \max_w \sum (y_i \ln h(x_i) + (1 - y_i) \ln (1 - h(x_i))) \\
    =& \arg \min_w \sum (- y_i \ln h(x_i) - (1 - y_i) \ln (1 - h(x_i)))
\end{aligned}$$

因此，一个合适的 loss function 为：

$$\boxed{
    J(w) = \sum_{i=1}^m (- y_i \ln h(x_i) - (1 - y_i) \ln (1 - h(x_i)))
}$$

然后无脑 GD 就完了！

# 分类评估方法

## 混淆矩阵

|  | 实际为真 | 实际为假 |
| - | - | - |
| **预测为真** | 真正例 TP | 伪正例 FP |
| **预测为假** | 伪反例 FN | 真反例 TN |

我们有以下常用的指标 / 方式，用于评估一个分类器：

### 系列 1

- **准确率 (Accuracy)**：

$$\text{Accuracy} = \frac {TP + TN} {TP + TN + FP + FN}$$

- **精确率 (Precision)**：

$$\text{Precision} = \frac {TP} {TP + FP}$$

- **召回率 (Recall)**：

$$\text{Recall} = \frac {TP} {TP + FN}$$

- 想同时关注 Precision 和 Recall，不妨用它们的调和平均数 **F1-score**：

$$\text{F1-score} = \frac 2 {\frac 1 {\text{Precision}} + \frac 1 {\text{Recall}}}$$

### 系列 2

- **真阳性率 (True Positive Rate, TPR)**：

$$\text{TPR} = \frac {TP} {TP + FN}  = \text{Recall}$$

- **假阳性率 (False Positive Rate, FPR)**：

$$\text{FPR} = \frac {FP} {TN + FP}$$

- **ROC 曲线 (Receiver operating characteristic curve)**：一种可视化工具，以 FPR 为横轴，TPR 为纵轴，画出分类器的评估结果。

<img src="https://upload.wikimedia.org/wikipedia/commons/6/6b/Roccurves.png" width=400>

- **AUC (Area Under the Curve)**：字面意思。
  - $\text{AUC} = 1$ 说明分类器的性能完美。
  - $\text{AUC} = \frac 1 2$ 说明分类器拉完了，跟瞎蒙没区别。
  - $\text{AUC} < \frac 1 2$ 表面上好像拉完了，但如果你直接把分类器结果取反，那就 $\text{AUC} > \frac 1 2$ 就有价值了。