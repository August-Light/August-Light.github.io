---
title: 'Day 1 初识线性'
date: 2025-12-22
permalink: /posts/2025/12/2025-12-22-Day-1-初识线性/
excerpt: "线性代数从来不是**矩阵代数**。我们应当理解并赞美线性代数带给我们的优雅结构。"
tags:
  - Math
---

线性代数从来不是**矩阵代数**。我们不应该纠结于“矩阵的 $\det$ 怎么算”这种琐碎的细节，而应当理解并赞美线性代数带给我们的优雅结构。

# References

- [MIT 线性代数公开课](https://www.bilibili.com/video/BV1ix411f7Yp/)
  - Gilbert Strang https://math.mit.edu/~gs/
  - [民间的配套笔记 - 三少爷的键](https://zhuanlan.zhihu.com/p/45707832)
- [3B1B 线性代数的本质](https://www.bilibili.com/video/BV1ys411472E/)
  - [民间的配套笔记 - 三少爷的键​](https://zhuanlan.zhihu.com/p/110244610)

# 初识矩阵

我们小学二年级就学过像这样的线性方程组

$$\begin{cases}
    2x + y = 0 \\
    -x + 2y = 3 \\
\end{cases}$$

这个方程组事实上有一个很清晰的“物理意义”：

$$x \begin{bmatrix} 2 \\ -1 \end{bmatrix} + y \begin{bmatrix} 1 \\ 2 \end{bmatrix} = \begin{bmatrix} 0 \\ 3 \end{bmatrix}$$

即：怎么把向量 $\begin{bmatrix} 0 \\ 3 \end{bmatrix}$ 拆成 $\begin{bmatrix} 2 \\ -1 \end{bmatrix}$ 和 $\begin{bmatrix} 1 \\ 2 \end{bmatrix}$ 的**线性组合**。

还有一种理解：把原先坐标系下的**标准基** $\begin{bmatrix} 1 \\ 0 \end{bmatrix}$ 和 $\begin{bmatrix} 0 \\ 1 \end{bmatrix}$ 变换到 $\begin{bmatrix} 2 \\ -1 \end{bmatrix}$ 和 $\begin{bmatrix} 1 \\ 2 \end{bmatrix}$ 时，$\begin{bmatrix} x \\ y \end{bmatrix}$ 会被同步变换到 $\begin{bmatrix} 0 \\ 3 \end{bmatrix}$：

$$\begin{aligned}
    & x \begin{bmatrix} 1 \\ 0 \end{bmatrix} & + & y \begin{bmatrix} 0 \\ 1 \end{bmatrix} & = & \begin{bmatrix} x \\ y \end{bmatrix} \\
    \xRightarrow{\text{Transform}} \ & x \begin{bmatrix} 2 \\ -1 \end{bmatrix} & + & y \begin{bmatrix} 1 \\ 2 \end{bmatrix} & = & \begin{bmatrix} 0 \\ 3 \end{bmatrix} \\
\end{aligned}$$

这种变换被称为**线性变换**，当然我们现在还没有严格定义它。

刚刚提到的标准基指的是只有第 $i$ 维是 $1$，其余维都是 $0$ 的向量，记为 $\vec e_i$。有标准基，我们就能确定整个坐标系。

像这样的线性变换，我们可以用**矩阵 (matrix)** 来表示，只要在对应位置依次填入系数即可：

$$\begin{bmatrix} 2 & 1 \\ -1 & 2 \end{bmatrix} \begin{bmatrix} x \\ y \end{bmatrix} = \begin{bmatrix} 0 \\ 3 \end{bmatrix}$$

即可以被表示为这样的形式：

$$\mathbf A \vec x = \vec b$$

- 理解 1：$\mathbf A$ 是系数矩阵，$\vec b$ 是我想拼出的向量，$\vec x$ 是我想求的若干未知数组合出的向量，即线性组合中的系数。
- 理解 2：$\vec x$ 是原来的向量，$\mathbf A$ 是一个线性变换，$\vec b$ 是变换后的向量。

注意 $\mathbf A$ 不一定是方阵（$n \times n$ 的矩阵），因为我的未知数数量和方程数量不一定相等。

# 主线任务：$\mathbf A \vec x = \vec b$

> 给定 $\mathbf A, \vec b$，方程 $\mathbf A \vec x = \vec b$ 有什么性质？
>
> - 解有几个？是无解、唯一解、好几个解、无数解？
> - 怎么解出具体的解？

我们依旧从向量线性组合的角度来想。

比如说，如果是 2D 向量，若打包成矩阵的两个向量是共线的，则它俩怎么都不可能组合出这条线以外的向量。但是其余情况是可以的。

再比如说，$3$ 个 3D 向量，若共面则不可能组合出该面以外的向量。对于更糟的情况，三个向量共线，那么不可能组合出这条线以外的向量。

【定义】一堆向量 $\vec a_1, \cdots, \vec a_n$ 线性组合出的所有向量称为它们**张成的空间 (span)**。对于矩阵 $\mathbf A$，它的所有向量张成的空间称为 $\mathbf A$ 的 **column space**，记作 $C(\mathbf A)$。

那么我们可以得到一个直觉：大部分情况下只要 $\mathbf A$ 性质不错，我们根本不用管 $\vec b$。我们给这种不错的性质起名为**非奇异 (non-singular)**，如果是坏矩阵则称为**奇异 (singular)**。奇异性只对方阵定义。

【定义】一个方阵是 non-singular 的，当且仅当它的 $n$ 个向量**线性无关 (linear independent)**，即其中的任何一个都不能被其他几个的线性组合表示。

经过小转化，还有一种等价的表述：$\mathbf A \vec x = \vec 0$ 存在 $\vec x = \vec 0$ 以外的解。（提示：$\vec a = \vec b + \vec c$ 可以记为 $- \vec a + \vec b + \vec c = 0$）

【定义】对于矩阵 $\mathbf A$，方程 $\mathbf A \vec x = \vec 0$ 的解集称为 $\mathbf A$ 的 **null space**，记作 $N(\mathbf A)$。

当 $\mathbf A$ non-singular 时，$N(\mathbf A)$ 仅含有零向量。

不难发现：

- 对于 non-singular 矩阵 $\mathbf A$，对于任意 $\vec b$ 都**存在且仅存在一个** $\vec x$ 满足方程。
- 对于 singular 矩阵 $\mathbf A$，这种情况显然性质不大好。
  - 若 $\vec b \not \in C(\mathbf A)$，此时无解；
  - 若 $\vec b \in C(\mathbf A)$，此时无数解。关于此时解的结构，会在后面的内容中讨论。

关于具体怎么解出解，会在 Gauss-Jordan 消元法一段中聊。

# 矩阵乘法

> 小提示：$m \times n$ 矩阵说的是该矩阵有 $m$ 行 $n$ 列。行在前，列在后。

我有点好奇，能不能对一个向量施加两次线性变换？即：

$$\mathbf A (\mathbf B \vec x)$$

让我们 clarify 一下其中的细节。
- 第一步：对于一个 $p$ 维向量 $\vec x$，我们可以施加一个 $n \times p$ 的矩阵 $\mathbf B$，把它变成 $n$ 维向量。
- 第二步：对于 $n$ 维向量 $\mathbf B \vec x$，我们可以施加一个 $m \times n$ 的矩阵 $\mathbf A$，把它变成 $m$ 维向量。

但是这不禁让人想问，我能不能直接一步到位啊？即直接搞一个 $m \times p$ 的矩阵 $\mathbf C$，使得 $\mathbf C \vec x = \mathbf A (\mathbf B \vec x)$？

当然可以！

根据对于矩阵乘向量的理解，我们追踪所有基向量的去处。

设 $\mathbf B = \begin{bmatrix} \vec b_1 & \vec b_2 & \cdots & \vec b_p \end{bmatrix}$，则对于每个基向量 $\vec e_i$，有：

$$\mathbf C \vec e_i = \mathbf A \mathbf B \vec e_i = \mathbf A \vec b_i$$

$$\mathbf C = \begin{bmatrix} \mathbf A \vec b_1 & \mathbf A \vec b_2 & \cdots & \mathbf A \vec b_p \end{bmatrix}$$

（这个记法代表把这些向量以列的形式摆在一起形成矩阵）

进一步展开这个式子，我们可以得到以下结论：

> 对于 $m \times n$ 矩阵 $\mathbf A$ 和 $n \times p$ 矩阵 $\mathbf B$，可以构造 $m \times p$ 矩阵 $\mathbf C$，使得对于任意 $p$ 维向量 $\vec x$，有
>
> $$\mathbf A (\mathbf B \vec x) = \mathbf C \vec x$$
>
> 具体构造为：
>
> $$\mathbf C_{i,j} = \sum_{k=1}^n \mathbf A_{i,k} \mathbf B_{k,j}$$

此时，我们就可以认为 $\mathbf C$ 是 $\mathbf A \times \mathbf B$ 的结果，这就是**矩阵乘法**的定义。

## 矩阵乘法的结合律

根据刚才的定义，我们可以得到：

$$\mathbf A (\mathbf B \vec x) = (\mathbf A \mathbf B) \vec x$$

这起码说明矩阵和向量之间的乘法是有结合律的。那纯粹的矩阵之间乘法有没有结合律？即，以下式子是否成立？

$$\mathbf A (\mathbf B \mathbf C) = (\mathbf A \mathbf B) \mathbf C$$

当然是成立的。因为不管哪边，都代表“先施加 $\mathbf C$，再施加 $\mathbf B$，最后施加 $\mathbf A$”的这个操作，不会因为先算哪个乘法而导致顺序的变化。**因此矩阵乘法具有结合律**。

（当然如果你计算功底很好，你也可以直接从 $c_{i,j} = \sum a_{i,k} b_{k,j}$ 的定义直接无脑推）

但是千万注意，顺序是重要的。对于任意两个矩阵 $\mathbf A, \mathbf B$，“$\mathbf A \mathbf B = \mathbf B \mathbf A$”是大概率不成立的，即**矩阵乘法不具有交换律**。

# 单位矩阵与逆矩阵

矩阵乘矩阵还是矩阵，这种乘法还有结合律。按照群论的思路，我们应该寻找**单位元**和**逆元**了。

## Identity Matrix

我们将矩阵乘法的乘法单位元称为**单位矩阵 (identity matrix)**。单位矩阵 $\mathbf I$ 应该满足

$$\mathbf I \mathbf A = \mathbf A \mathbf I = \mathbf A$$

显然要满足这个方程，$\mathbf I, \mathbf A$ 都只可能是 $n \times n$ 的方阵。

$\mathbf I$ 的作用应该相当于什么都不做。对于任意基向量 $\vec e_i$，都应该有：

$$\mathbf I \vec e_i = \vec e_i$$

显然

$$\mathbf I = \begin{bmatrix} \vec e_1 & \vec e_2 & \cdots & \vec e_n \end{bmatrix}$$

即

$$\mathbf I = \begin{bmatrix}
    1 & 0 & \cdots & 0 \\
    0 & 1 & \cdots & 0 \\
    \vdots & \vdots & \ddots & \vdots \\
    0 & 0 & \cdots & 1 \\
\end{bmatrix}$$

## Inverse of a Matrix

矩阵 $\mathbf A$ 的乘法逆元（即它的**逆矩阵 (inverse)**）若存在，应该满足

$$\mathbf A \mathbf A^{-1} = \mathbf A^{-1} \mathbf A = \mathbf I$$

显然 $\mathbf A$ 和 $\mathbf A^{-1}$ 都得是 $n \times n$ 的方阵。

思考一下 $\mathbf A^{-1}$ 何时存在（若存在，我们称 $\mathbf A$ **可逆 (invertible)**）。我们从最基本的式子开始：对于任意向量 $\vec b$，

$$\begin{aligned}
    \mathbf A \vec x &= \vec b \\
    \mathbf A^{-1} \mathbf A \vec x &= \mathbf A^{-1} \vec b \\
    \vec x &= \mathbf A^{-1} \vec b \\
\end{aligned}$$

由于此时 $\vec x$ 能被 $\vec b$ 唯一确定，因此 $\mathbf A$ 必须是 non-singular 的，即 non-singular 是 invertible 的充分条件。

进一步地，non-singular 是不是 invertible 的充要条件？我们可以如下构造：

对于 $i = 1 \dots n$，令 $\vec x_i$ 为 $\mathbf A \vec x = \vec e_i$ 的唯一解。构造矩阵

$$\mathbf B = \begin{bmatrix} \vec x_1 & \vec x_2 & \cdots & \vec x_n \end{bmatrix}$$

计算

$$\mathbf A \mathbf B = \begin{bmatrix} \mathbf A \vec x_1 & \mathbf A \vec x_2 & \cdots & \mathbf A \vec x_n \end{bmatrix} = \begin{bmatrix} \vec e_1 & \vec e_2 & \cdots & \vec e_n \end{bmatrix} = \mathbf I$$

即 $\mathbf B$ 确实是 $\mathbf A$ 的逆矩阵。

因此我们证明：**方阵 $\mathbf A$ 可逆当且仅当它 non-singular**。

# Vector Space

【定义】若一个向量集合对向量加法和数乘封闭，则这个向量集合是一个 **vector space**。

不难验证，对于任意矩阵 $\mathbf A$，$C(\mathbf A)$ 和 $N(\mathbf A)$ 都是 vector space，所以我们叫它们“space”确实是合理的。~~先射箭后画靶属于是~~

若一个 vector space 的子集还是 vector space，则这个子集称为原来空间的一个**子空间 (subspace)**。

对于一个 vector space，它的两个 subspace 的交集还是一个 subspace。

## 线性变换的严谨定义

借助 vector space，我们可以为线性变换作出严谨的定义：

【定义】一个从 vector space $V$ 向 vector space $W$ 映射的函数 $T$ 是一个**线性变换**（**线性映射**），当且仅当它对任意数 $\lambda$ 和 $V$ 中任意向量 $\vec u, \vec v$ 满足这样的性质：

$$\begin{cases}
    T(\vec u + \vec v) = T(\vec u) + T(\vec v) \\
    T(\lambda \vec v) = \lambda T(\vec v) \\
\end{cases}$$

进一步可以导出：

$$T\left( \sum c_i \vec v_i \right) = \sum c_i T(\vec v_i)$$

# Basis & Dimension

【定义】对于线性空间 $V$，若一组**线性无关**的向量可以**张成** $V$，则这组向量是 $V$ 的一组**基 (basis)**。

【定义】一组基中的向量个数，称为这个线性空间的**维数 (dimension)**。对于线性空间 $V$，其维数记为 $\dim V$。

# Transpose

我们观察矩阵乘法的表达式：

$$\mathbf C_{i,j} = \sum_k \mathbf A_{i,k} \mathbf B_{k,j}$$

这里的指标似乎有某种对称性：$i,k,j$ 似乎可以反一下变成 $j,k,i$。

我们定义一个针对矩阵的操作 $(\cdot)^T$，满足 $(\cdot)^T_{j,i} = (\cdot)_{i,j}$，这个操作称为**转置 (transpose)**。

$$\mathbf C^T_{j,i} = \sum_k \mathbf A^T_{k,i} \mathbf B^T_{j,k}$$

把 $i,j$ 互换一下：

$$\mathbf C^T_{i,j} = \sum_k \mathbf B^T_{i,k} \mathbf A^T_{k,j}$$

$$\mathbf C^T = \mathbf B^T \mathbf A^T$$

$$\boxed{
    (\mathbf A \mathbf B)^T = \mathbf B^T \mathbf A^T
}$$

转置可以看成是翻转行列的一个 trick——你可以在翻转行列的同时保持矩阵乘法的性质。