---
title: '推断'
date: 2026-02-23
permalink: /posts/2026/02/2026-02-23-推断/
excerpt: "概念最难的一章。"
tags:
  - Math
  - Stat
---

# 置信区间

我有一个（连续的）总体参数 $\theta$，我们取样本 $X$ 后通过某种方式估计它的值为 $\hat \theta$。怎么描述这个估计有多准呢？

我们没有办法说 $\theta = \hat \theta$ 的概率是多少——一个点的概率没有意义。我们只能说，对于一个 $\hat \theta$ 附近的区间 $[l, r]$（**其中 $l,r$ 是关于 $X$ 的函数，是随机变量**），$\theta \in [l, r]$ 的概率是 $p$。

确切地说，对于任意 $\theta$，若我们无数次取样 $X$（**样本之间独立**），对应的 $[l,r]$ 成功覆盖到 $\theta$ 的概率是 $p$：

$$p = P(\theta \in [l(X), r(X)]), \text{where } X \text{ is random}$$

这个 $p$ 被称为**置信区间 (confidence interval)** $[l,r]$ 的**置信水平 (confidence level)**，我们说我们有 $p$ 的**信心**让 $[l,r]$ 覆盖 $\theta$。

在统计学的习惯中，我们往往更关心**覆盖不到的概率**，称为**显著性水平 (significance level)**，记作 $\alpha$：

$$\boxed{
    \alpha = P(\theta \not \in [l(X), r(X)])
}$$

## 对称分布下的置信区间

若 $\hat \theta$ 服从关于 $\theta$ 对称的分布，我们一般用以下格式描述置信区间：

$$\hat \theta \pm \text{margin of error}$$

众所周知，统计学很喜欢用标准差来描述东西。对于 $\text{margin of error}$ 的范围，我们可以把它写成一个 z-score：

$$P\left( \frac {\hat \theta - \theta} {\text{SD}(\hat \theta)} \in [-k^*, k^*] \right) \overset{?}{=} 1 - \alpha$$

但是很遗憾，$\text{SD}(\hat \theta)$ 的确切值也经常是未知的。因此我们只能使用估计的标准差 $\widehat{\text{SD}}(\hat \theta)$，称为**标准误**，记作 $\text{SE}(\hat \theta)$：

$$P\left( \frac {\hat \theta - \theta} {\text{SE}(\hat \theta)} \in [-k^*, k^*] \right) = 1 - \alpha$$

置信区间即为：

$$\hat \theta \pm k^* \times \text{SE}(\hat \theta)$$

## 容易犯的错误

- 对于这次算出来的 $[l,r]$，真实 $\theta$ 有 $1 - \alpha$ 的概率落在 $[l,r]$ 内？
  - 真实 $\theta$ **不是随机变量**，这次算出来的置信区间也**不是随机变量**，根本没有概率这一说，要说也就只有 $0$ 或 $1$。这个是或否是确定的，只是我们不知道。
- 对于这次算出来的 $[l,r]$，我以后重复好多次实验，$\theta$ 有 $1 - \alpha$ 的概率落在 $[l,r]$ 内？
  - $[l,r]$ 只是基于这个样本算出来的，和其他样本没有关系。

## 常用 $\text{SE}$ 计算

$$\text{SE}(\hat p) = \sqrt{\frac {p (1 - p)} n} \implies \widehat{\text{SE}}(\hat p) = \sqrt{\frac {\hat p (1 - \hat p)} n}$$

由于 $\text{SE}$ 与要求的 $p$ 直接相关，不可能求得。因此只能退而求其次，把 $\hat p$ **直接代入** $p$ 得到一个估计值 $\widehat{\text{SE}}$。

---

$$\begin{aligned}
    & \text{SE}(\hat p_1 - \hat p_2) = \sqrt{\frac {p_1 (1 - p_1)} {n_1} + \frac {p_2 (1 - p_2)} {n_2}} \\
    \implies & \widehat{\text{SE}}(\hat p_1 - \hat p_2) = \sqrt{\frac {\hat p_1 (1 - \hat p_1)} {n_1} + \frac {\hat p_2 (1 - \hat p_2)} {n_2}} \\
\end{aligned}$$


和上面那个同理。

---

TODO: 这个咋用？

$$\text{SE}(\bar x) = \frac s {\sqrt n}$$

## 例子

> 「Example 6.8」
>
> 一名调查员想要了解所有成年人中已完全接种新冠疫苗并接种加强针的比例。
>
> 如果要求结果在 $96\%$ 的置信水平下误差不超过 $\pm 0.03$，那么应该选择多少名成年人作为样本？
>
> - 假设每个人是否接种疫苗相互独立。
> - 假设该二项分布足够大，可以看作正态分布。

此处由于是正态分布，我们用明确的字母 $z^*$ 代替 $k^*$。我们可以计算出 $z^*$：

$$z^* = \text{invNorm}\left( \frac {1 - 96\%} 2 \right) \approx -2.05375$$

根据题目条件：

$$\begin{aligned}
    \lvert z^* \rvert \times \text{SE}(\hat p) & \le 0.03 \\
    \frac {\sqrt{p (1 - p)}} {\sqrt n} & \le \frac {0.03} {\lvert z^* \rvert} \\
\end{aligned}$$

根据 AM-GM 不等式，分子是 $\le \frac 1 2$ 的（在 $p = \frac 1 2$ 取等）。我们只需要保证分子最大的时候也依然满足限制：

$$\frac 1 {2 \sqrt n} \le \frac {0.03} {\lvert z^* \rvert}$$

解得 $n \ge 1171.63$。最终答案要向上取整为 $\boxed{1172}$。

书上由于只保留了两位小数所以最后一步算出来 $1167.4$，有点搞笑了。

> 「Example 6.12」
>
> 研究人员独立地随机抽取了 $1017$ 名居住在城市地区的成年人和 $801$ 名居住在农村地区的成年人作为简单样本。在受访者中，$612$ 名城市居民和 $137$ 名农村居民表示支持政府投入更多资金扩大高速互联网接入。
>
> 使用 $99\%$ 的置信区间估计支持政府投入更多资金扩大高速互联网接入的城市居民和农村居民比例的差异。
>
> - 假设该二项分布足够大，可以看作正态分布。

$$z^* = \text{invNorm}\left( \frac {1 - 99\%} 2 \right) \approx -2.57583$$

$$\widehat{\text{SE}}(\hat p_1 - \hat p_2) = \sqrt{\frac {\hat p_1 (1 - \hat p_1)} {n_1} + \frac {\hat p_2 (1 - \hat p_2)} {n_2}} \approx 0.0203136$$

置信区间即为：

$$(\hat p_1 - \hat p_2) \pm z^* \times \widehat{\text{SE}} \approx \boxed{0.431 \pm 0.052}$$

# 显著性

## $H_0$ 与 $H_a$

一般来说，对于一个问题我们会有一个默认立场。比如，对于一种药的药效，我们的默认立场可以是「药无效」。默认立场也叫做**零假设 (null hypothesis)**，记作 $H_0$。零假设中经常使用**等号**来代表「无差异」。比如，用了药的效果等于没用药的效果。

与零假设相对的是**备择假设 (alternative hypothesis)**，记作 $H_a$。备择假设中经常使用**不等号**来代表「有差异」。

数学上说，$H_0$ 和 $H_a$ 的地位是相同的。但是实践中，我们往往把希望否决的立场放在 $H_0$，把希望得到的立场放在 $H_a$。因此，我们从来不说「接受 $H_0$」，我们只说「**拒绝** $H_0$」或「**不拒绝** $H_0$」。

## $p$-value

> 怎么根据手上的证据，判断要不要拒绝 $H_0$？

我们计算**当 $H_0$ 为真的前提下，出现更「离谱」结果的概率**，称为 $p$-value，符号用 $p$ 表示。**注意「离谱」是人为定义的标准，在不同方法下离谱的程度不同** TODO:。

当「$p$-value 非常小」的时候，说明出现更离谱结果的概率非常小，即若 $H_0$ 为真的话我们手上的结果已经非常离谱了，此时拒绝 $H_0$。

什么叫「$p$-value 非常小」？我们可以人为设定一个 $p$-value 的上限 $\alpha$ 称为**显著性水平**（往往是 $5\%$ 之类的很小的数字），若 $p < \alpha$ 我们就认为 $p$ 非常小。

$\alpha$ 也可以理解为：「$H_0$ 明明是对的但是我误判把它判错了」的概率。这种误判被称为**第一类错误 (Type I Error)**。

$$\alpha = P(\text{reject } H_0 \mid H_0 \text{ is true})$$

反过来，「$H_0$ 明明是错的但是我误判把它判对了」被称为**第二类错误 (Type II Error)**，发生概率记作 $\beta$。

$$\beta = P(\text{fail to reject } H_0 \mid H_0 \text{ is false})$$

|  | $H_0$ 是对的 | $H_0$ 是错的 |
| - | - | - |
| 拒绝 $H_0$ | **Type I Error** ($\alpha$) | Correct decision ($1 - \beta$) |
| 不拒绝 $H_0$ | Correct decision ($1 - \alpha$) | **Type II Error** ($\beta$) |

注意，$\alpha$ 是我们人为预先设定的固定值，但是 $\beta$ 不是固定值，而是一个**关于总体参数的函数**（不同的总体参数会带来不同的 $\beta$ 值）。

不犯第二类错误的概率被称为**统计功效 / 检验功效 (power of the test)**：

$$\text{power} = P(\text{reject } H_0 \mid H_0 \text{ is false}) = 1 - \beta$$